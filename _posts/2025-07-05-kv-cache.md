---
layout: post
title:  KV cache
date:   2025-07-05 00:00:00 +0000
---


KV cache is using the values of KV dot product from the cache which would save time and resources.

$attention(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V$

In a normal attention, the matrix multiplication will be of $O(n^2)$. But KV cache will make it to linear time $O(n)$. So the prefill stage with KV cache will ideally be faster.

